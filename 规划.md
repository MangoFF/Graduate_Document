# 总的规划

这一次回去，事实上需要干这样几件事情：
1. 完成AllReduce的量化工作，如果能实现这个，并且在性能上十分的有优势，我相信，会取得相当好的结果！提速度也会很明显
2. 完成毕业设计
   1. 构造目标数据集 - 如何和目标对齐
   2. 全Int8训练流程 - 如何设计一个Int8 全训练流程 量化相关
   3. 负反馈训练（如何达成负反馈训练，模型发现自己错了的时候，应该如何纠正自己（构造不同的Loss函数，应对这种学习）
   4. 使用已有的资源FineTune ChatGLM3 6B 
   5. 支持更长的上下文（如何支持更长的上下文，在有限的设备上跑出最大的Token数目）
   6. 效果：有哪些效果（分数，效果，榜单等等）
   7. 开源这个工作

想做的很多，我觉得核心的部分可能就这么多：
1. Int8 全流程量化训练
2. 负反馈训练
3. 支持更长的上下文


中间用到的技术：
1. 多模型管理服务框架
2. 文本到SQL的FineTune框架
3. 检索增强搜索的策略和方法
4. 数据驱动的Agent框架

时间上是真的非常的紧急，几个分厂重要的时间点：
    1. 3月份盲审，留给你写论文的时间其实并不多（两个月，60天，假设你要写5w字，你每天都要写将近一千字）
    2. AllReduce可以当成是你学习C++的一个梯子，你就把这个当成是学习C++的一个方式就好了。
    3. 你一直想做一个比较伟大的事情，这次这个事情是可以做的比较伟大的。

产出文档和代码：
1. 量化训练的代码，包括：
2. 负反馈训练的代码，包括：
3. 支持更长的上下文的代码，包括：


